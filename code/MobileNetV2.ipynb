{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2: Inverted Residuals and Linear Bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call [SSDLite](). Additionally, we demonstrate how to build [mobile semantic segmentation models]() through a reduced form of DeepLabv3 which we call Mobile DeepLabv3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main contribution is a novel layer module: [the inverted residual with linear bottleneck]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module takes as an input a low-dimensional compressed representation which is first expanded to high dimension and filtered with a lightweight depthwise convolution. Features are subsequently projected back to a low-dimensional representation with a linear convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, this convolutional module is particularly suitable for mobile designs, because it allows to significantly reduce the memory footprint(内存占用) needed during inference by never fully materializing large intermediate tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preliminaries, discussion and intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Depthwise Separable Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Standard convolution : $h_{i} \\times w_{i} \\times d_{i}$ input tensor $L_{i}$\n",
    "* deotgwuse separable : depthwise and $1 \\times 1$ pointwise convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer is called a depthwise convolution, it performs lightweight filtering by applying a single convolutional filter per input channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The second layer is a 1 × 1 convolution, called a pointwise convolution, which is responsible for building new fea- tures through computing linear combinations of the in- put channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Linear Bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a deep neural network consisting of n layers $L_{i}$ each of which has an [activation tensor]() of dimensions $h_{i} × w_{i} × d_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU6???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c71e970b376e5910de56d332af36cb508b823811ace826c2f1193ceeb2dcc3e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
